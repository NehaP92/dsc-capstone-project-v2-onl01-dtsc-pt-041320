# CAPSTONE PROJECT

# Differencial Diagnosis Between COVID, Viral Pneumonia, and Tuberculosis



The outbreak of Novel Coronavirus (SARS-COV-2) has taken over all our lives ever since the pandemic hit last year. The difficult part at the beginning of the outbreak was to detect the virus since the symptoms are shared among other common desieses and infections. One of these include pneumonia.

> Deep learning AI models have been used in the past to detect pneumonia, and have been reported to gain about 90% accuracy. [1]

While discussing about pneumonia, it is paramount to understand that pneumonia is often misdiagnosed as tuberculosis. [2]

This project explores building different models that would detect if a lung X-Ray correctly diagnoses COVID-19, Pneumonia, Tuberculosis, Viral Pneumonia, or if it is a normal Chest X-ray. It also explores the varios regions of the x-ray that the model is looking in for an accurate diagnosis.

> Accuracy, Precision, and Recall have been used as the deciding factor for the best model

Precision would be important when the model is used to distinguish between the different desieses whoes diagnosis are often confused with another, while recall becomes significant while determining if the desiese is present at all.


## Data

The Data for this project has been generated by combining the X-Ray Images from 2 sources. One dataset consisted of the X-ray Images differentiating COVID, Viral Pneumonia and Normal Chest X-rays, while the other data set had chest x-rays for TB and normal. The normal x-rays from each data set were not combined since there could be a possibility that the X-rays not showing pneumonia could have TB and vis-a-versa. 

**img** (Data)

The images were then renamed and combined for preprocessing using simple coding in Python. To load the data in google colab notebook, file path data frame was also created using python.

Figure 2 shows the class imbalance in the data set. To minimie the effect of class imbalance, the models were built with the class weights parameter.

**figure class imbalance**

The ImageDataGenerator object was created with rescalling of 1./255, after which the images were loaded in using keras's flow_from_dataframe function, which yeilded 4687 images classified into 5 classes. Since one of the images in the file was corrupted, that image is omited out of any further process.

The train-val-test split consist of 3795,422, and 469 images respectively.


## Methodology

- Data Pre-processing
- Explore and optimize various pre-trained models to use as base model to build on.
- Finalize  the best model based on performance measures (Accuracy, Precision, Recall) and model explanation


## Dummy Model

A dummy model is first created using scikit learn's DummyClassifier to compare to and improve upon the results. The DummyClassifier bore very poor results with only 18% accuracy and 25% precision.


> **3 Pre-trained models were explored to use as a base model to build on. Various optimizers, number of layers, drop out, and LeakyReLu layers were also explored using different parameters for optimization**


## Best Pre-Trained Model Transfer VGG16 - Accuracy 97%

The parameters which resulted in the best model, out of 6, with pre-trained VGG16 base were:

> Additional layer on top of the base model: 1 dense layer, activation - 'relu'\
Optimizer: Adam
epochs: 50
batch size: 64
callbacks: Early stopping with patience 3
learning rate: 0.001
loss: categorical crossentropy
metric: accuracy
final layer: dense, activation 'softmax'

Table 1 shows the classifcation report and Figure 3 shows the confusion matrix for this model when run on the test data.

**Table 1** (classification repot)

**Figure 3** (confusion matrix)

Figure 4 shows the train and validation accuracy and loss plots while the model was being trained.

**Figure 4**

The plot shows that the model is likely being overfitted and needs additional tweeking in the design and number of layers to stop the model from being over-trained.

The model can now be explained using the lime package. It explains the model by highlighting the area of the image that was used to classify. This helps in making better judgements and confidence that the model will accurately classify a new image that was not used in training by looking at the right areas. Figure 5 shows the lime explaination of all the bad predictions that were made using this model. The total number bad predictions were 15 out of the 422 test images fed to the model.

**Figure 5**

Figure 6 shows the lime explaination of randomn 5 images from the test set that were classified using this model.

**Figure 6**

Based on these explainations, we may find that most of the bad predictions are not looking in the right areas. however, the the probability of true negative is looking inthe right area almost every time.

To improve these explainations, it thus becomes important to utilize a mask to help the model look into the correct area. While the model acheived a 96% accuracy, it would be more trustable with an addition of masks to further guide the model


## Best Pre-trained Model Tranfer Xception - Accuracy 94%

The parameters which resulted in the best model with pre-trained Xception base were:

> Additional layer on top of the base model: 4 dense layer, activation - 'relu', LeakyReLu, Dropout\
Optimizer: Adam
epochs: 50
batch size: 64
callbacks: Early stopping with patience 3
learning rate: 0.001
loss: categorical crossentropy
metric: accuracy
final layer: dense, activation 'softmax'

Table 2 shows the classifcation report and Figure 7 shows the confusion matrix for this model when run on the test data.

**Table 2** (classification repot)

**Figure 7** (confusion matrix)

Figure 8 shows the train and validation accuracy and loss plots while the model was being trained.

**Figure 8**

Based on the precision and recall values, the model would need to be optimized to make Viral pneumonia classification more trustable.


## Best Pre-trained Model Tranfer DenseNet121 - Accuracy 95%

The parameters which resulted in the best model with pre-trained DenseNet121 base were:

> Additional layer on top of the base model: 4 dense layer, activation - 'relu', LeakyReLu, Dropout\
Optimizer: Adam
epochs: 50
batch size: 64
callbacks: Early stopping with patience 3
learning rate: 0.001
loss: categorical crossentropy
metric: accuracy
final layer: dense, activation 'softmax'

Table 3 shows the classifcation report and Figure 9 shows the confusion matrix for this model when run on the test data.

**Table 3** (classification repot)

**Figure 9** (confusion matrix)

Figure 10 shows the train and validation accuracy and loss plots while the model was being trained.

**Figure 10**

Based on these plots, and the performance measures, we can say that out model is doing a good job in accurately classifying the diagnosis, and with high precission and recall for each class.

Although the accuracy is not as high as the VGG16 model, this model is more trustable since it is not overfit, and has high precision and recall values for all classes.

To further strenthen our case, lime explanation was plotted for bad-predictions (Figure 11) and 5 random images (Figure 12) from the test dataset.

**Figure 11**

**Figure 12**

Comparing these explanations with VGG16 model, we have a clear winner here since the model generated with DenseNet121 looks into more relevant areas for all predictions compared to VGG16, which makes it more trustable.


## Recommendations

- With acceptabley high accuracy of more than 95%, and high precision and recall for covid and pneumonia patients, it is recommended to consider using an AI based model for accurate diagnosis.

- Looking at comparatively lower accuracy, precision and recall with TB patients, it is recommended to invest in further research in gathering more data and building further on the model to be able to use the model to detect TB.

- Although the model shows high accuracy, it is important and recommended to use a combination of other symptoms either by knowledge or integrating it with the model for better diagnosis and patient care.


## Future Work

- Building a Dashboard/Application that would accept any format of the Xray, preprocess and use the model for diagnosis, and include the area of the X-ray used for the result (explaination)

- Explore other models by building by scratch, and including image augmentation, and creating masks to improve the predictability of the model

- Include other symptoms in the model to aid in better diagnosis


## References
[1] https://towardsdatascience.com/detecting-covid-19-induced-pneumonia-from-chest-x-rays-with-transfer-learning-an-implementation-311484e6afc1

[2] Aiyesha Sadiya, Anusha V Illur, Aekhata Nanda, Eshwar Rao, Vidyashree K P, Mansoor Ahmed. *Differential Diagnosis of Tuberculosis and
Pneumonia using Machine Learning*